version: '3.8'

services:
  # Tauros AI Bot Service
  tauros-bot:
    build:
      context: ./tauros-bot
      dockerfile: Dockerfile
    container_name: tauros-bot
    environment:
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
      - OPENAI_KEY=${OPENAI_KEY}
      - USE_OPENAI_IF_FAIL=${USE_OPENAI_IF_FAIL:-true}
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./tauros-bot/logs:/app/logs
      - ./tauros-bot/data:/app/data
      - ./tauros-bot/temp:/app/temp
    depends_on:
      - redis
      - ollama
    restart: unless-stopped
    networks:
      - tauros-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Tauros AI Backend Service
  tauros-backend:
    build:
      context: ./tauros-backend
      dockerfile: Dockerfile
    container_name: tauros-backend
    environment:
      - HOST=0.0.0.0
      - PORT=8000
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
      - OPENAI_KEY=${OPENAI_KEY}
      - USE_OPENAI_IF_FAIL=${USE_OPENAI_IF_FAIL:-true}
      - REDIS_URL=redis://redis:6379
      - API_KEY=${API_KEY}
    volumes:
      - ./tauros-backend/logs:/app/logs
      - ./tauros-backend/data:/app/data
    ports:
      - "8000:8000"
    depends_on:
      - redis
      - ollama
    restart: unless-stopped
    networks:
      - tauros-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Ollama AI Service
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_ORIGINS=*
    restart: unless-stopped
    networks:
      - tauros-network
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    # GPU support (uncomment if you have NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # Redis Cache Service
  redis:
    image: redis:7-alpine
    container_name: tauros-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    restart: unless-stopped
    networks:
      - tauros-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: tauros-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - tauros-backend
    restart: unless-stopped
    networks:
      - tauros-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring (Optional - Prometheus)
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: tauros-prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #     - prometheus_data:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #     - '--storage.tsdb.path=/prometheus'
  #     - '--web.console.libraries=/etc/prometheus/console_libraries'
  #     - '--web.console.templates=/etc/prometheus/consoles'
  #   restart: unless-stopped
  #   networks:
  #     - tauros-network

volumes:
  ollama_data:
    driver: local
  redis_data:
    driver: local
  nginx_logs:
    driver: local
  # prometheus_data:
  #   driver: local

networks:
  tauros-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16